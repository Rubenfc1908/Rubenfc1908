{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Rubenfc1908/Rubenfc1908/blob/main/Mushrooms.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SQ4UnKU8FSMt"
      },
      "source": [
        "instalar PyTorch y torchvision\n",
        "Configura el entorno para usar una GPU si está disponible."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LpQYTgEXCVfc",
        "outputId": "82ad12cf-ce7a-4d53-d6d5-63cc5463509c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.1.0+cu118)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (0.16.0+cu118)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2023.6.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch) (2.1.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision) (1.23.5)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torchvision) (2.31.0)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision) (9.4.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (2023.11.17)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install torch torchvision"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SFIsFjUoF0YZ"
      },
      "source": [
        "Carga de Datos:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ulp5bRB5FRPt",
        "outputId": "b82bae3c-d3e7-4fa7-db74-f4e256d2a164"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3aH8zx5nONdV"
      },
      "source": [
        "Carga de Imágenes: Lee las imágenes desde los directorios especificados y las almacena en una lista.\n",
        "\n",
        "Preprocesamiento de Imágenes: Incluye transformaciones como redimensionamiento y normalización, lo cual es crucial para preparar las imágenes para su uso en modelos de aprendizaje profundo.\n",
        "\n",
        "Carga de Etiquetas: Lee las etiquetas desde los archivos correspondientes en formato de texto, interpretando y almacenando la información necesaria para la detección de objetos."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "ckkSCRKZJ2oL"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import os\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader, Dataset  # Agregar esta línea\n",
        "import cv2\n",
        "import os\n",
        "import torchvision.transforms as transforms\n",
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "\n",
        "# Resto de tu código principal\n",
        "\n",
        "\n",
        "\n",
        "# Transformación para las imágenes\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToPILImage(),\n",
        "    transforms.Resize((416, 416)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "])\n",
        "\n",
        "def load_images_and_labels(images_dir, labels_dir):\n",
        "    images = []\n",
        "    annotations = []\n",
        "\n",
        "    # Cargar y preprocesar imágenes\n",
        "    for img_filename in sorted(os.listdir(images_dir)):\n",
        "        img_path = os.path.join(images_dir, img_filename)\n",
        "        img = cv2.imread(img_path)\n",
        "        img = transform(img)  # Aplicar la transformación\n",
        "        images.append(img)\n",
        "\n",
        "        # Leer etiquetas (archivos de texto)\n",
        "        label_filename = '.'.join(img_filename.split('.')[:-1]) + '.txt'\n",
        "        label_path = os.path.join(labels_dir, label_filename)\n",
        "\n",
        "        if os.path.exists(label_path):\n",
        "            with open(label_path, 'r') as file:\n",
        "                boxes = []\n",
        "                max_width = 0\n",
        "                max_height = 0\n",
        "\n",
        "                #for line in file:\n",
        "                    #class_id, x_center, y_center, width, height = map(float, line.split())\n",
        "                    #print(f\"Clase: {class_id}, x_center: {x_center}, y_center: {y_center}, Ancho: {width}, Alto: {height}\")\n",
        "\n",
        "                for line in file:\n",
        "                    class_id, x_center, y_center, width, height = map(float, line.split())\n",
        "                    boxes.append((class_id, x_center, y_center, width, height))\n",
        "                    max_width = max(max_width, width)\n",
        "                    max_height = max(max_height, height)\n",
        "\n",
        "                # Aplicar padding para igualar dimensiones\n",
        "                padded_boxes = []\n",
        "                for box in boxes:\n",
        "                    class_id, x_center, y_center, width, height = box\n",
        "                    width_padding = max_width - width\n",
        "                    height_padding = max_height - height\n",
        "                    padded_box = (\n",
        "                        class_id,\n",
        "                        x_center,\n",
        "                        y_center,\n",
        "                        width + width_padding,\n",
        "                        height + height_padding,\n",
        "                    )\n",
        "                    padded_boxes.append(padded_box)\n",
        "\n",
        "                annotations.append((img_filename, padded_boxes))\n",
        "\n",
        "    return images, annotations\n",
        "\n",
        "# Define la función de collate personalizada\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "from torch import nn\n",
        "\n",
        "# Define la función de collate personalizada\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "from torch import nn\n",
        "\n",
        "\n",
        "\n",
        "# Rutas a los directorios de imágenes y etiquetas\n",
        "base_dir = '/content/drive/My Drive/Mushrooms/'\n",
        "\n",
        "train_images, train_annotations = load_images_and_labels(os.path.join(base_dir, 'train/images'), os.path.join(base_dir, 'train/labels'))\n",
        "valid_images, valid_annotations = load_images_and_labels(os.path.join(base_dir, 'valid/images'), os.path.join(base_dir, 'valid/labels'))\n",
        "test_images, test_annotations = load_images_and_labels(os.path.join(base_dir, 'test/images'), os.path.join(base_dir, 'test/labels'))\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TA6jC2IrabDA"
      },
      "source": [
        "Saber cuantas clases hay"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lwUmylnMaLKP",
        "outputId": "4554914d-cc59-459c-ed2d-794eba3ca656"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Número de clases, incluyendo el fondo: 3\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "def count_classes(labels_dir):\n",
        "    class_ids = set()\n",
        "\n",
        "    # Iterar sobre cada archivo de etiquetas\n",
        "    for label_file in os.listdir(labels_dir):\n",
        "        if label_file.endswith('.txt'):\n",
        "            with open(os.path.join(labels_dir, label_file), 'r') as file:\n",
        "                for line in file:\n",
        "                    class_id = line.split()[0]\n",
        "                    class_ids.add(class_id)\n",
        "\n",
        "    return len(class_ids)\n",
        "\n",
        "# Reemplaza esto con la ruta a tu carpeta de etiquetas\n",
        "labels_dir = '/content/drive/My Drive/Mushrooms/train/labels/'\n",
        "num_classes = count_classes(labels_dir)\n",
        "\n",
        "# Imprime el número de clases (agrega 1 para la clase de fondo)\n",
        "print(\"Número de clases, incluyendo el fondo:\", num_classes + 1)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AoVJH086OZuX"
      },
      "source": [
        "Este código carga un modelo Faster R-CNN preentrenado y luego modifica la última capa de clasificación para que coincida con el número de clases en tu conjunto de datos."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "s3caLPu5OZ8y"
      },
      "outputs": [],
      "source": [
        "import torchvision\n",
        "from torchvision.models.detection import fasterrcnn_resnet50_fpn\n",
        "\n",
        "# Cargar el modelo preentrenado\n",
        "model = fasterrcnn_resnet50_fpn(pretrained=True)\n",
        "\n",
        "# Si tu conjunto de datos tiene un número diferente de clases, ajusta la cabeza del clasificador\n",
        "num_classes = 3  # por ejemplo, si tienes dos clases. Asegúrate de incluir la clase de fondo\n",
        "in_features = model.roi_heads.box_predictor.cls_score.in_features\n",
        "\n",
        "# Reemplaza la cabeza del clasificador con una nueva para el número de clases en tu conjunto de datos\n",
        "model.roi_heads.box_predictor = torchvision.models.detection.faster_rcnn.FastRCNNPredictor(in_features, num_classes)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aDvd22f7b3Gh"
      },
      "source": [
        "Afinar el modelo R-CNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "SPH5JCXDb4es"
      },
      "outputs": [],
      "source": [
        "# Congelar todas las capas del modelo\n",
        "for param in model.parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "# Permitir el entrenamiento de las capas superiores\n",
        "# Por ejemplo, para la cabeza del clasificador en Faster R-CNN\n",
        "for param in model.roi_heads.parameters():\n",
        "    param.requires_grad = True\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iU7F0qo1c4cs"
      },
      "source": [
        "Dividir tu conjunto de datos en entrenamiento, validación y prueba, y luego crear DataLoaders en PyTorch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iULXQcxLrkwm",
        "outputId": "1595e146-d295-47bb-8746-351afbee7134"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Imágenes sin etiquetas: set()\n",
            "Etiquetas sin imágenes: set()\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "images_dir = '/content/drive/My Drive/Mushrooms/train/images/'\n",
        "labels_dir = '/content/drive/My Drive/Mushrooms/train/labels/'\n",
        "\n",
        "# Listar todos los archivos de imagen\n",
        "image_files = set([file.split('.')[0] for file in os.listdir(images_dir)])\n",
        "\n",
        "# Listar todos los archivos de etiquetas\n",
        "label_files = set([file.split('.')[0] for file in os.listdir(labels_dir)])\n",
        "\n",
        "# Encontrar imágenes sin etiquetas correspondientes\n",
        "unmatched_images = image_files - label_files\n",
        "unmatched_labels = label_files - image_files\n",
        "\n",
        "print(\"Imágenes sin etiquetas:\", unmatched_images)\n",
        "print(\"Etiquetas sin imágenes:\", unmatched_labels)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B8B28cHncpjv",
        "outputId": "cfd2d833-0db9-4d88-81f3-f65005575fa5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total de imágenes: 246\n",
            "Total de etiquetas: 246\n",
            "Total de imágenes: 5\n",
            "Total de etiquetas: 5\n",
            "Total de imágenes: 5\n",
            "Total de etiquetas: 5\n"
          ]
        }
      ],
      "source": [
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "class CustomDataset(Dataset):\n",
        "    def __init__(self, images, labels):\n",
        "        self.images = images\n",
        "        self.labels = labels\n",
        "        print(\"Total de imágenes:\", len(self.images))\n",
        "        print(\"Total de etiquetas:\", len(self.labels))\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        print(\"Accediendo al índice:\", idx)\n",
        "        return self.images[idx], self.labels[idx]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.images)\n",
        "\n",
        "\n",
        "\n",
        "# Crear conjuntos de datos\n",
        "train_dataset = CustomDataset(train_images, train_annotations)\n",
        "valid_dataset = CustomDataset(valid_images, valid_annotations)\n",
        "test_dataset = CustomDataset(test_images, test_annotations)\n",
        "\n",
        "# Crear DataLoaders\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "valid_loader = DataLoader(valid_dataset, batch_size=32, shuffle=False)\n",
        "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ycCDUxbNdx1r"
      },
      "source": [
        "Configuración del Proceso de Entrenamiento"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bSucjbW_Culi",
        "outputId": "6a21a539-c48b-4c02-9362-9768cfa13edd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=FasterRCNN_ResNet50_FPN_Weights.COCO_V1`. You can also use `weights=FasterRCNN_ResNet50_FPN_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Imágenes sin etiquetas: set()\n",
            "Etiquetas sin imágenes: set()\n",
            "Total de imágenes: 246\n",
            "Total de etiquetas: 246\n",
            "Total de imágenes: 5\n",
            "Total de etiquetas: 5\n",
            "Total de imágenes: 5\n",
            "Total de etiquetas: 5\n",
            "Total de imágenes: 246\n",
            "Total de etiquetas: 246\n",
            "Longitud de train_loader: 8\n",
            "Cantidad total de imágenes en entrenamiento: 246\n",
            "Cantidad total de etiquetas en entrenamiento: 246\n",
            "Accediendo al índice: 15\n",
            "Accediendo al índice: 57\n",
            "Accediendo al índice: 113\n",
            "Accediendo al índice: 227\n",
            "Accediendo al índice: 198\n",
            "Accediendo al índice: 77\n",
            "Accediendo al índice: 11\n",
            "Accediendo al índice: 184\n",
            "Accediendo al índice: 70\n",
            "Accediendo al índice: 6\n",
            "Accediendo al índice: 7\n",
            "Accediendo al índice: 107\n",
            "Accediendo al índice: 215\n",
            "Accediendo al índice: 195\n",
            "Accediendo al índice: 0\n",
            "Accediendo al índice: 151\n",
            "Accediendo al índice: 119\n",
            "Accediendo al índice: 236\n",
            "Accediendo al índice: 176\n",
            "Accediendo al índice: 132\n",
            "Accediendo al índice: 228\n",
            "Accediendo al índice: 88\n",
            "Accediendo al índice: 173\n",
            "Accediendo al índice: 179\n",
            "Accediendo al índice: 58\n",
            "Accediendo al índice: 120\n",
            "Accediendo al índice: 38\n",
            "Accediendo al índice: 115\n",
            "Accediendo al índice: 108\n",
            "Accediendo al índice: 135\n",
            "Accediendo al índice: 192\n",
            "Accediendo al índice: 8\n",
            "Accediendo al índice: 92\n",
            "Accediendo al índice: 99\n",
            "Accediendo al índice: 217\n",
            "Accediendo al índice: 24\n",
            "Accediendo al índice: 129\n",
            "Accediendo al índice: 166\n",
            "Accediendo al índice: 237\n",
            "Accediendo al índice: 20\n",
            "Accediendo al índice: 4\n",
            "Accediendo al índice: 157\n",
            "Accediendo al índice: 121\n",
            "Accediendo al índice: 188\n",
            "Accediendo al índice: 80\n",
            "Accediendo al índice: 36\n",
            "Accediendo al índice: 233\n",
            "Accediendo al índice: 189\n",
            "Accediendo al índice: 177\n",
            "Accediendo al índice: 223\n",
            "Accediendo al índice: 84\n",
            "Accediendo al índice: 134\n",
            "Accediendo al índice: 5\n",
            "Accediendo al índice: 169\n",
            "Accediendo al índice: 112\n",
            "Accediendo al índice: 182\n",
            "Accediendo al índice: 37\n",
            "Accediendo al índice: 18\n",
            "Accediendo al índice: 161\n",
            "Accediendo al índice: 226\n",
            "Accediendo al índice: 75\n",
            "Accediendo al índice: 148\n",
            "Accediendo al índice: 65\n",
            "Accediendo al índice: 232\n",
            "Accediendo al índice: 204\n",
            "Accediendo al índice: 28\n",
            "Accediendo al índice: 76\n",
            "Accediendo al índice: 218\n",
            "Accediendo al índice: 39\n",
            "Accediendo al índice: 116\n",
            "Accediendo al índice: 101\n",
            "Accediendo al índice: 168\n",
            "Accediendo al índice: 104\n",
            "Accediendo al índice: 72\n",
            "Accediendo al índice: 111\n",
            "Accediendo al índice: 167\n",
            "Accediendo al índice: 73\n",
            "Accediendo al índice: 83\n",
            "Accediendo al índice: 202\n",
            "Accediendo al índice: 48\n",
            "Accediendo al índice: 94\n",
            "Accediendo al índice: 63\n",
            "Accediendo al índice: 190\n",
            "Accediendo al índice: 110\n",
            "Accediendo al índice: 164\n",
            "Accediendo al índice: 61\n",
            "Accediendo al índice: 142\n",
            "Accediendo al índice: 155\n",
            "Accediendo al índice: 55\n",
            "Accediendo al índice: 67\n",
            "Accediendo al índice: 31\n",
            "Accediendo al índice: 81\n",
            "Accediendo al índice: 33\n",
            "Accediendo al índice: 221\n",
            "Accediendo al índice: 174\n",
            "Accediendo al índice: 17\n",
            "Accediendo al índice: 207\n",
            "Accediendo al índice: 130\n",
            "Accediendo al índice: 71\n",
            "Accediendo al índice: 183\n",
            "Accediendo al índice: 56\n",
            "Accediendo al índice: 30\n",
            "Accediendo al índice: 64\n",
            "Accediendo al índice: 152\n",
            "Accediendo al índice: 238\n",
            "Accediendo al índice: 19\n",
            "Accediendo al índice: 194\n",
            "Accediendo al índice: 45\n",
            "Accediendo al índice: 196\n",
            "Accediendo al índice: 105\n",
            "Accediendo al índice: 51\n",
            "Accediendo al índice: 87\n",
            "Accediendo al índice: 156\n",
            "Accediendo al índice: 125\n",
            "Accediendo al índice: 201\n",
            "Accediendo al índice: 153\n",
            "Accediendo al índice: 103\n",
            "Accediendo al índice: 29\n",
            "Accediendo al índice: 175\n",
            "Accediendo al índice: 23\n",
            "Accediendo al índice: 243\n",
            "Accediendo al índice: 234\n",
            "Accediendo al índice: 54\n",
            "Accediendo al índice: 42\n",
            "Accediendo al índice: 97\n",
            "Accediendo al índice: 178\n",
            "Accediendo al índice: 143\n",
            "Accediendo al índice: 122\n",
            "Accediendo al índice: 211\n",
            "Accediendo al índice: 43\n",
            "Accediendo al índice: 25\n",
            "Accediendo al índice: 210\n",
            "Accediendo al índice: 46\n",
            "Accediendo al índice: 59\n",
            "Accediendo al índice: 203\n",
            "Accediendo al índice: 35\n",
            "Accediendo al índice: 66\n",
            "Accediendo al índice: 12\n",
            "Accediendo al índice: 220\n",
            "Accediendo al índice: 118\n",
            "Accediendo al índice: 82\n",
            "Accediendo al índice: 230\n",
            "Accediendo al índice: 124\n",
            "Accediendo al índice: 78\n",
            "Accediendo al índice: 212\n",
            "Accediendo al índice: 229\n",
            "Accediendo al índice: 14\n",
            "Accediendo al índice: 85\n",
            "Accediendo al índice: 32\n",
            "Accediendo al índice: 231\n",
            "Accediendo al índice: 131\n",
            "Accediendo al índice: 93\n",
            "Accediendo al índice: 3\n",
            "Accediendo al índice: 16\n",
            "Accediendo al índice: 222\n",
            "Accediendo al índice: 165\n",
            "Accediendo al índice: 139\n",
            "Accediendo al índice: 1\n",
            "Accediendo al índice: 214\n",
            "Accediendo al índice: 245\n",
            "Accediendo al índice: 2\n",
            "Accediendo al índice: 100\n",
            "Accediendo al índice: 140\n",
            "Accediendo al índice: 95\n",
            "Accediendo al índice: 186\n",
            "Accediendo al índice: 154\n",
            "Accediendo al índice: 127\n",
            "Accediendo al índice: 79\n",
            "Accediendo al índice: 21\n",
            "Accediendo al índice: 50\n",
            "Accediendo al índice: 240\n",
            "Accediendo al índice: 136\n",
            "Accediendo al índice: 206\n",
            "Accediendo al índice: 91\n",
            "Accediendo al índice: 13\n",
            "Accediendo al índice: 102\n",
            "Accediendo al índice: 114\n",
            "Accediendo al índice: 68\n",
            "Accediendo al índice: 197\n",
            "Accediendo al índice: 126\n",
            "Accediendo al índice: 162\n",
            "Accediendo al índice: 52\n",
            "Accediendo al índice: 137\n",
            "Accediendo al índice: 144\n",
            "Accediendo al índice: 172\n",
            "Accediendo al índice: 145\n",
            "Accediendo al índice: 90\n",
            "Accediendo al índice: 96\n",
            "Accediendo al índice: 44\n",
            "Accediendo al índice: 239\n",
            "Accediendo al índice: 69\n",
            "Accediendo al índice: 185\n",
            "Accediendo al índice: 106\n",
            "Accediendo al índice: 41\n",
            "Accediendo al índice: 60\n",
            "Accediendo al índice: 128\n",
            "Accediendo al índice: 193\n",
            "Accediendo al índice: 123\n",
            "Accediendo al índice: 89\n",
            "Accediendo al índice: 191\n",
            "Accediendo al índice: 149\n",
            "Accediendo al índice: 27\n",
            "Accediendo al índice: 180\n",
            "Accediendo al índice: 146\n",
            "Accediendo al índice: 86\n",
            "Accediendo al índice: 181\n",
            "Accediendo al índice: 158\n",
            "Accediendo al índice: 53\n",
            "Accediendo al índice: 225\n",
            "Accediendo al índice: 26\n",
            "Accediendo al índice: 242\n",
            "Accediendo al índice: 49\n",
            "Accediendo al índice: 147\n",
            "Accediendo al índice: 141\n",
            "Accediendo al índice: 244\n",
            "Accediendo al índice: 163\n",
            "Accediendo al índice: 208\n",
            "Accediendo al índice: 150\n",
            "Accediendo al índice: 199\n",
            "Accediendo al índice: 241\n",
            "Accediendo al índice: 235\n",
            "Accediendo al índice: 40\n",
            "Accediendo al índice: 9\n",
            "Accediendo al índice: 200\n",
            "Accediendo al índice: 138\n",
            "Accediendo al índice: 98\n",
            "Accediendo al índice: 171\n",
            "Accediendo al índice: 205\n",
            "Accediendo al índice: 213\n",
            "Accediendo al índice: 74\n",
            "Accediendo al índice: 216\n",
            "Accediendo al índice: 10\n",
            "Accediendo al índice: 187\n",
            "Accediendo al índice: 219\n",
            "Accediendo al índice: 224\n",
            "Accediendo al índice: 160\n",
            "Accediendo al índice: 209\n",
            "Accediendo al índice: 133\n",
            "Accediendo al índice: 117\n",
            "Accediendo al índice: 159\n",
            "Accediendo al índice: 34\n",
            "Accediendo al índice: 47\n",
            "Accediendo al índice: 62\n",
            "Accediendo al índice: 170\n",
            "Accediendo al índice: 22\n",
            "Accediendo al índice: 109\n",
            "Accediendo al índice: 38\n",
            "Accediendo al índice: 218\n",
            "Accediendo al índice: 49\n",
            "Accediendo al índice: 70\n",
            "Accediendo al índice: 37\n",
            "Accediendo al índice: 13\n",
            "Accediendo al índice: 189\n",
            "Accediendo al índice: 242\n",
            "Accediendo al índice: 29\n",
            "Accediendo al índice: 4\n",
            "Accediendo al índice: 225\n",
            "Accediendo al índice: 71\n",
            "Accediendo al índice: 23\n",
            "Accediendo al índice: 111\n",
            "Accediendo al índice: 21\n",
            "Accediendo al índice: 168\n",
            "Accediendo al índice: 109\n",
            "Accediendo al índice: 156\n",
            "Accediendo al índice: 166\n",
            "Accediendo al índice: 128\n",
            "Accediendo al índice: 39\n",
            "Accediendo al índice: 217\n",
            "Accediendo al índice: 98\n",
            "Accediendo al índice: 30\n",
            "Accediendo al índice: 175\n",
            "Accediendo al índice: 152\n",
            "Accediendo al índice: 52\n",
            "Accediendo al índice: 124\n",
            "Accediendo al índice: 18\n",
            "Accediendo al índice: 174\n",
            "Accediendo al índice: 88\n",
            "Accediendo al índice: 219\n",
            "Accediendo al índice: 164\n",
            "Accediendo al índice: 58\n",
            "Accediendo al índice: 66\n",
            "Accediendo al índice: 67\n",
            "Accediendo al índice: 233\n",
            "Accediendo al índice: 35\n",
            "Accediendo al índice: 223\n",
            "Accediendo al índice: 104\n",
            "Accediendo al índice: 198\n",
            "Accediendo al índice: 143\n",
            "Accediendo al índice: 170\n",
            "Accediendo al índice: 167\n",
            "Accediendo al índice: 36\n",
            "Accediendo al índice: 169\n",
            "Accediendo al índice: 120\n",
            "Accediendo al índice: 231\n",
            "Accediendo al índice: 151\n",
            "Accediendo al índice: 129\n",
            "Accediendo al índice: 105\n",
            "Accediendo al índice: 202\n",
            "Accediendo al índice: 144\n",
            "Accediendo al índice: 159\n",
            "Accediendo al índice: 40\n",
            "Accediendo al índice: 194\n",
            "Accediendo al índice: 171\n",
            "Accediendo al índice: 3\n",
            "Accediendo al índice: 15\n",
            "Accediendo al índice: 244\n",
            "Accediendo al índice: 197\n",
            "Accediendo al índice: 102\n",
            "Accediendo al índice: 97\n",
            "Accediendo al índice: 62\n",
            "Accediendo al índice: 91\n",
            "Accediendo al índice: 220\n",
            "Accediendo al índice: 214\n",
            "Accediendo al índice: 133\n",
            "Accediendo al índice: 132\n",
            "Accediendo al índice: 161\n",
            "Accediendo al índice: 46\n",
            "Accediendo al índice: 131\n",
            "Accediendo al índice: 86\n",
            "Accediendo al índice: 50\n",
            "Accediendo al índice: 107\n",
            "Accediendo al índice: 208\n",
            "Accediendo al índice: 77\n",
            "Accediendo al índice: 43\n",
            "Accediendo al índice: 193\n",
            "Accediendo al índice: 127\n",
            "Accediendo al índice: 94\n",
            "Accediendo al índice: 25\n",
            "Accediendo al índice: 16\n",
            "Accediendo al índice: 213\n",
            "Accediendo al índice: 100\n",
            "Accediendo al índice: 95\n",
            "Accediendo al índice: 145\n",
            "Accediendo al índice: 28\n",
            "Accediendo al índice: 56\n",
            "Accediendo al índice: 53\n",
            "Accediendo al índice: 126\n",
            "Accediendo al índice: 122\n",
            "Accediendo al índice: 22\n",
            "Accediendo al índice: 24\n",
            "Accediendo al índice: 80\n",
            "Accediendo al índice: 160\n",
            "Accediendo al índice: 89\n",
            "Accediendo al índice: 81\n",
            "Accediendo al índice: 59\n",
            "Accediendo al índice: 184\n",
            "Accediendo al índice: 32\n",
            "Accediendo al índice: 34\n",
            "Accediendo al índice: 99\n",
            "Accediendo al índice: 108\n",
            "Accediendo al índice: 121\n",
            "Accediendo al índice: 45\n",
            "Accediendo al índice: 19\n",
            "Accediendo al índice: 215\n",
            "Accediendo al índice: 115\n",
            "Accediendo al índice: 17\n",
            "Accediendo al índice: 10\n",
            "Accediendo al índice: 147\n",
            "Accediendo al índice: 176\n",
            "Accediendo al índice: 200\n",
            "Accediendo al índice: 177\n",
            "Accediendo al índice: 192\n",
            "Accediendo al índice: 158\n",
            "Accediendo al índice: 195\n",
            "Accediendo al índice: 190\n",
            "Accediendo al índice: 236\n",
            "Accediendo al índice: 245\n",
            "Accediendo al índice: 211\n",
            "Accediendo al índice: 42\n",
            "Accediendo al índice: 68\n",
            "Accediendo al índice: 183\n",
            "Accediendo al índice: 41\n",
            "Accediendo al índice: 123\n",
            "Accediendo al índice: 1\n",
            "Accediendo al índice: 51\n",
            "Accediendo al índice: 134\n",
            "Accediendo al índice: 162\n",
            "Accediendo al índice: 205\n",
            "Accediendo al índice: 153\n",
            "Accediendo al índice: 237\n",
            "Accediendo al índice: 11\n",
            "Accediendo al índice: 5\n",
            "Accediendo al índice: 207\n",
            "Accediendo al índice: 75\n",
            "Accediendo al índice: 54\n",
            "Accediendo al índice: 140\n",
            "Accediendo al índice: 163\n",
            "Accediendo al índice: 235\n",
            "Accediendo al índice: 7\n",
            "Accediendo al índice: 135\n",
            "Accediendo al índice: 196\n",
            "Accediendo al índice: 138\n",
            "Accediendo al índice: 191\n",
            "Accediendo al índice: 227\n",
            "Accediendo al índice: 20\n",
            "Accediendo al índice: 117\n",
            "Accediendo al índice: 116\n",
            "Accediendo al índice: 78\n",
            "Accediendo al índice: 87\n",
            "Accediendo al índice: 212\n",
            "Accediendo al índice: 79\n",
            "Accediendo al índice: 154\n",
            "Accediendo al índice: 137\n",
            "Accediendo al índice: 230\n",
            "Accediendo al índice: 201\n",
            "Accediendo al índice: 60\n",
            "Accediendo al índice: 210\n",
            "Accediendo al índice: 148\n",
            "Accediendo al índice: 96\n",
            "Accediendo al índice: 234\n",
            "Accediendo al índice: 188\n",
            "Accediendo al índice: 90\n",
            "Accediendo al índice: 203\n",
            "Accediendo al índice: 172\n",
            "Accediendo al índice: 180\n",
            "Accediendo al índice: 114\n",
            "Accediendo al índice: 74\n",
            "Accediendo al índice: 221\n",
            "Accediendo al índice: 47\n",
            "Accediendo al índice: 146\n",
            "Accediendo al índice: 240\n",
            "Accediendo al índice: 232\n",
            "Accediendo al índice: 110\n",
            "Accediendo al índice: 14\n",
            "Accediendo al índice: 178\n",
            "Accediendo al índice: 228\n",
            "Accediendo al índice: 157\n",
            "Accediendo al índice: 226\n",
            "Accediendo al índice: 63\n",
            "Accediendo al índice: 209\n",
            "Accediendo al índice: 2\n",
            "Accediendo al índice: 84\n",
            "Accediendo al índice: 130\n",
            "Accediendo al índice: 229\n",
            "Accediendo al índice: 0\n",
            "Accediendo al índice: 173\n",
            "Accediendo al índice: 64\n",
            "Accediendo al índice: 72\n",
            "Accediendo al índice: 222\n",
            "Accediendo al índice: 55\n",
            "Accediendo al índice: 93\n",
            "Accediendo al índice: 85\n",
            "Accediendo al índice: 155\n",
            "Accediendo al índice: 142\n",
            "Accediendo al índice: 6\n",
            "Accediendo al índice: 243\n",
            "Accediendo al índice: 182\n",
            "Accediendo al índice: 57\n",
            "Accediendo al índice: 185\n",
            "Accediendo al índice: 61\n",
            "Accediendo al índice: 216\n",
            "Accediendo al índice: 76\n",
            "Accediendo al índice: 206\n",
            "Accediendo al índice: 9\n",
            "Accediendo al índice: 101\n",
            "Accediendo al índice: 106\n",
            "Accediendo al índice: 239\n",
            "Accediendo al índice: 187\n",
            "Accediendo al índice: 125\n",
            "Accediendo al índice: 224\n",
            "Accediendo al índice: 112\n",
            "Accediendo al índice: 113\n",
            "Accediendo al índice: 118\n",
            "Accediendo al índice: 179\n",
            "Accediendo al índice: 150\n",
            "Accediendo al índice: 26\n",
            "Accediendo al índice: 186\n",
            "Accediendo al índice: 33\n",
            "Accediendo al índice: 44\n",
            "Accediendo al índice: 27\n",
            "Accediendo al índice: 141\n",
            "Accediendo al índice: 12\n",
            "Accediendo al índice: 241\n",
            "Accediendo al índice: 119\n",
            "Accediendo al índice: 83\n",
            "Accediendo al índice: 31\n",
            "Accediendo al índice: 73\n",
            "Accediendo al índice: 139\n",
            "Accediendo al índice: 204\n",
            "Accediendo al índice: 92\n",
            "Accediendo al índice: 181\n",
            "Accediendo al índice: 199\n",
            "Accediendo al índice: 65\n",
            "Accediendo al índice: 48\n",
            "Accediendo al índice: 8\n",
            "Accediendo al índice: 103\n",
            "Accediendo al índice: 69\n",
            "Accediendo al índice: 149\n",
            "Accediendo al índice: 165\n",
            "Accediendo al índice: 82\n",
            "Accediendo al índice: 238\n",
            "Accediendo al índice: 136\n",
            "Accediendo al índice: 0\n",
            "Accediendo al índice: 1\n",
            "Accediendo al índice: 2\n",
            "Accediendo al índice: 3\n",
            "Accediendo al índice: 4\n",
            "Epoch 2/2, Train Loss: 3.0828, Valid Loss: 0.0000\n"
          ]
        }
      ],
      "source": [
        "import cv2\n",
        "import os\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader, Dataset  # Agregar esta línea\n",
        "import cv2\n",
        "import os\n",
        "import torchvision.transforms as transforms\n",
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "\n",
        "# Resto de tu código principal\n",
        "\n",
        "\n",
        "\n",
        "# Transformación para las imágenes\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToPILImage(),\n",
        "    transforms.Resize((416, 416)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "])\n",
        "\n",
        "def load_images_and_labels(images_dir, labels_dir):\n",
        "    images = []\n",
        "    targets = []\n",
        "\n",
        "    # Cargar y preprocesar imágenes y etiquetas\n",
        "    for img_filename in sorted(os.listdir(images_dir)):\n",
        "        # Carga de la imagen\n",
        "        img_path = os.path.join(images_dir, img_filename)\n",
        "        img = cv2.imread(img_path)\n",
        "        img = transform(img)\n",
        "        images.append(img)\n",
        "\n",
        "        # Preparar las etiquetas\n",
        "        label_filename = '.'.join(img_filename.split('.')[:-1]) + '.txt'\n",
        "        label_path = os.path.join(labels_dir, label_filename)\n",
        "\n",
        "        boxes = []\n",
        "        labels = []\n",
        "        if os.path.exists(label_path):\n",
        "            with open(label_path, 'r') as file:\n",
        "                for line in file:\n",
        "                    class_id, x_center, y_center, width, height = map(float, line.split())\n",
        "                    x_min = x_center - width / 2\n",
        "                    y_min = y_center - height / 2\n",
        "                    x_max = x_center + width / 2\n",
        "                    y_max = y_center + height / 2\n",
        "                    boxes.append([x_min, y_min, x_max, y_max])\n",
        "                    labels.append(class_id)\n",
        "\n",
        "            boxes = torch.as_tensor(boxes, dtype=torch.float32)\n",
        "            labels = torch.as_tensor(labels, dtype=torch.int64)\n",
        "            target = {'boxes': boxes, 'labels': labels}\n",
        "            targets.append(target)\n",
        "\n",
        "    return images, targets\n",
        "\n",
        "def collate_fn(batch):\n",
        "    images, targets = zip(*batch)\n",
        "    images = list(images)\n",
        "    # No intentes apilar los targets. Déjalos como una lista de diccionarios\n",
        "    return images, list(targets)\n",
        "\n",
        "\n",
        "# Define la función de collate personalizada\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "from torch import nn\n",
        "\n",
        "# Define la función de collate personalizada\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "from torch import nn\n",
        "\n",
        "\n",
        "\n",
        "# Rutas a los directorios de imágenes y etiquetas\n",
        "base_dir = '/content/drive/My Drive/Mushrooms/'\n",
        "\n",
        "train_images, train_annotations = load_images_and_labels(os.path.join(base_dir, 'train/images'), os.path.join(base_dir, 'train/labels'))\n",
        "valid_images, valid_annotations = load_images_and_labels(os.path.join(base_dir, 'valid/images'), os.path.join(base_dir, 'valid/labels'))\n",
        "test_images, test_annotations = load_images_and_labels(os.path.join(base_dir, 'test/images'), os.path.join(base_dir, 'test/labels'))\n",
        "\n",
        "import torchvision\n",
        "from torchvision.models.detection import fasterrcnn_resnet50_fpn\n",
        "\n",
        "# Cargar el modelo preentrenado\n",
        "model = fasterrcnn_resnet50_fpn(pretrained=True)\n",
        "\n",
        "# Si tu conjunto de datos tiene un número diferente de clases, ajusta la cabeza del clasificador\n",
        "num_classes = 3  # por ejemplo, si tienes dos clases. Asegúrate de incluir la clase de fondo\n",
        "in_features = model.roi_heads.box_predictor.cls_score.in_features\n",
        "\n",
        "# Reemplaza la cabeza del clasificador con una nueva para el número de clases en tu conjunto de datos\n",
        "model.roi_heads.box_predictor = torchvision.models.detection.faster_rcnn.FastRCNNPredictor(in_features, num_classes)\n",
        "\n",
        "# Congelar todas las capas del modelo\n",
        "for param in model.parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "# Permitir el entrenamiento de las capas superiores\n",
        "# Por ejemplo, para la cabeza del clasificador en Faster R-CNN\n",
        "for param in model.roi_heads.parameters():\n",
        "    param.requires_grad = True\n",
        "import os\n",
        "\n",
        "images_dir = '/content/drive/My Drive/Mushrooms/train/images/'\n",
        "labels_dir = '/content/drive/My Drive/Mushrooms/train/labels/'\n",
        "\n",
        "# Listar todos los archivos de imagen\n",
        "image_files = set([file.split('.')[0] for file in os.listdir(images_dir)])\n",
        "\n",
        "# Listar todos los archivos de etiquetas\n",
        "label_files = set([file.split('.')[0] for file in os.listdir(labels_dir)])\n",
        "\n",
        "# Encontrar imágenes sin etiquetas correspondientes\n",
        "unmatched_images = image_files - label_files\n",
        "unmatched_labels = label_files - image_files\n",
        "\n",
        "print(\"Imágenes sin etiquetas:\", unmatched_images)\n",
        "print(\"Etiquetas sin imágenes:\", unmatched_labels)\n",
        "\n",
        "\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "class CustomDataset(Dataset):\n",
        "    def __init__(self, images, labels):\n",
        "        self.images = images\n",
        "        self.labels = labels\n",
        "        print(\"Total de imágenes:\", len(self.images))\n",
        "        print(\"Total de etiquetas:\", len(self.labels))\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        print(\"Accediendo al índice:\", idx)\n",
        "        return self.images[idx], self.labels[idx]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.images)\n",
        "\n",
        "\n",
        "\n",
        "# Crear conjuntos de datos\n",
        "train_dataset = CustomDataset(train_images, train_annotations)\n",
        "valid_dataset = CustomDataset(valid_images, valid_annotations)\n",
        "test_dataset = CustomDataset(test_images, test_annotations)\n",
        "\n",
        "# Crear DataLoaders\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, collate_fn=collate_fn)\n",
        "valid_loader = DataLoader(valid_dataset, batch_size=32, shuffle=False, collate_fn=collate_fn)\n",
        "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
        "\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "import torch\n",
        "import torch.optim as optim\n",
        "\n",
        "# Definir un optimizador\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# Definir la función de pérdida\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "# Definir el dispositivo: Utiliza GPU si está disponible, de lo contrario usa CPU\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Mover el modelo al dispositivo seleccionado\n",
        "model = model.to(device)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Aplicar padding durante la carga de datos\n",
        "train_images, train_annotations = load_images_and_labels(images_dir, labels_dir)  # Utiliza load_images_and_labels\n",
        "\n",
        "# Crear un Dataset personalizado\n",
        "train_dataset = CustomDataset(train_images, train_annotations)\n",
        "\n",
        "# Usar esta función en tu DataLoader\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, collate_fn=collate_fn)\n",
        "print\n",
        "enumerate(train_loader)\n",
        "\n",
        "\n",
        "\n",
        "class CustomDataset(Dataset):\n",
        "    def __init__(self, images, labels):\n",
        "        self.images = images\n",
        "        self.labels = labels\n",
        "        assert len(self.images) == len(self.labels), \"La cantidad de imágenes y etiquetas debe ser la misma\"\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.images)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        if idx < len(self.images) and idx < len(self.labels):\n",
        "            return self.images[idx], self.labels[idx]\n",
        "        else:\n",
        "            raise IndexError(\"Índice fuera de rango\")\n",
        "\n",
        "num_epochs = 2  # Define aquí el número de épocas---------------------------------------------------------------------------------------------------------------------------------\n",
        "\n",
        "# Ciclo de entrenamiento\n",
        "print(f\"Longitud de train_loader: {len(train_loader)}\")\n",
        "print(f\"Cantidad total de imágenes en entrenamiento: {len(train_images)}\")\n",
        "print(f\"Cantidad total de etiquetas en entrenamiento: {len(train_annotations)}\")\n",
        "\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()  # Poner el modelo en modo de entrenamiento\n",
        "    train_loss = 0.0\n",
        "\n",
        "    for images, targets in train_loader:\n",
        "        images = list(image.to(device) for image in images)  # Mover las imágenes al dispositivo\n",
        "\n",
        "        # Mover también los targets al dispositivo\n",
        "        targets = [{k: v.to(device) for k, v in t.items()} for t in targets]\n",
        "\n",
        "        # Limpia los gradientes\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Forward pass\n",
        "        loss_dict = model(images, targets)  # El modelo espera una lista de imágenes y una lista de diccionarios de targets\n",
        "\n",
        "        # Las pérdidas son devueltas como un diccionario. Sumamos todas las pérdidas.\n",
        "        losses = sum(loss for loss in loss_dict.values())\n",
        "\n",
        "        # Backward pass y optimizar\n",
        "        losses.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        train_loss += losses.item()\n",
        "\n",
        "    # Calcular la pérdida promedio de entrenamiento\n",
        "    train_loss /= len(train_loader)\n",
        "\n",
        "    # Resto del código para validación...\n",
        "\n",
        "  # Validación\n",
        "    model.eval()\n",
        "    valid_loss = 0.0\n",
        "\n",
        "with torch.no_grad():\n",
        "    for images, targets_batch in valid_loader:\n",
        "        images = [img.to(device) for img in images]\n",
        "        processed_targets = []\n",
        "\n",
        "        for targets in targets_batch:\n",
        "            if isinstance(targets, dict):\n",
        "                processed_targets.append({k: v.to(device) for k, v in targets.items()})\n",
        "            else:\n",
        "                print(\"Error: El target no es un diccionario.\")\n",
        "\n",
        "        # Realiza la inferencia\n",
        "        outputs = model(images, processed_targets)\n",
        "        # Aquí, puedes calcular la pérdida y acumularla en valid_loss si es necesario\n",
        "\n",
        "# Calcula la pérdida promedio de validación\n",
        "valid_loss /= len(valid_loader)\n",
        "\n",
        "# Imprimir estadísticas de entrenamiento y validación\n",
        "print(f'Epoch {epoch+1}/{num_epochs}, Train Loss: {train_loss:.4f}, Valid Loss: {valid_loss:.4f}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q7TzEFTGQ3ZZ"
      },
      "outputs": [],
      "source": [
        "# Guardar el modelo entrenado\n",
        "torch.save(model.state_dict(), '/content/drive/My Drive/Mushrooms/modelo_entrenado.pth')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "gradio"
      ],
      "metadata": {
        "id": "hL7DoDGix8Fh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install gradio"
      ],
      "metadata": {
        "id": "HkoevFBZx9KH",
        "outputId": "114ed222-bbf6-4dfa-9581-8f60122a8da0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gradio in /usr/local/lib/python3.10/dist-packages (4.9.0)\n",
            "Requirement already satisfied: aiofiles<24.0,>=22.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (23.2.1)\n",
            "Requirement already satisfied: altair<6.0,>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (4.2.2)\n",
            "Requirement already satisfied: fastapi in /usr/local/lib/python3.10/dist-packages (from gradio) (0.105.0)\n",
            "Requirement already satisfied: ffmpy in /usr/local/lib/python3.10/dist-packages (from gradio) (0.3.1)\n",
            "Requirement already satisfied: gradio-client==0.7.2 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.7.2)\n",
            "Requirement already satisfied: httpx in /usr/local/lib/python3.10/dist-packages (from gradio) (0.25.2)\n",
            "Requirement already satisfied: huggingface-hub>=0.19.3 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.19.4)\n",
            "Requirement already satisfied: importlib-resources<7.0,>=1.3 in /usr/local/lib/python3.10/dist-packages (from gradio) (6.1.1)\n",
            "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (3.1.2)\n",
            "Requirement already satisfied: markupsafe~=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.1.3)\n",
            "Requirement already satisfied: matplotlib~=3.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (3.7.1)\n",
            "Requirement already satisfied: numpy~=1.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (1.23.5)\n",
            "Requirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (3.9.10)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from gradio) (23.2)\n",
            "Requirement already satisfied: pandas<3.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (1.5.3)\n",
            "Requirement already satisfied: pillow<11.0,>=8.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (9.4.0)\n",
            "Requirement already satisfied: pydantic>=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.5.2)\n",
            "Requirement already satisfied: pydub in /usr/local/lib/python3.10/dist-packages (from gradio) (0.25.1)\n",
            "Requirement already satisfied: python-multipart in /usr/local/lib/python3.10/dist-packages (from gradio) (0.0.6)\n",
            "Requirement already satisfied: pyyaml<7.0,>=5.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (6.0.1)\n",
            "Requirement already satisfied: semantic-version~=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.10.0)\n",
            "Requirement already satisfied: tomlkit==0.12.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.12.0)\n",
            "Requirement already satisfied: typer[all]<1.0,>=0.9 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.9.0)\n",
            "Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (4.9.0)\n",
            "Requirement already satisfied: uvicorn>=0.14.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.24.0.post1)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from gradio-client==0.7.2->gradio) (2023.6.0)\n",
            "Requirement already satisfied: websockets<12.0,>=10.0 in /usr/local/lib/python3.10/dist-packages (from gradio-client==0.7.2->gradio) (11.0.3)\n",
            "Requirement already satisfied: entrypoints in /usr/local/lib/python3.10/dist-packages (from altair<6.0,>=4.2.0->gradio) (0.4)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.10/dist-packages (from altair<6.0,>=4.2.0->gradio) (4.19.2)\n",
            "Requirement already satisfied: toolz in /usr/local/lib/python3.10/dist-packages (from altair<6.0,>=4.2.0->gradio) (0.12.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.19.3->gradio) (3.13.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.19.3->gradio) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.19.3->gradio) (4.66.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (4.46.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (1.4.5)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (3.1.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3.0,>=1.0->gradio) (2023.3.post1)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.0->gradio) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.14.5 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.0->gradio) (2.14.5)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.10/dist-packages (from typer[all]<1.0,>=0.9->gradio) (8.1.7)\n",
            "Requirement already satisfied: colorama<0.5.0,>=0.4.3 in /usr/local/lib/python3.10/dist-packages (from typer[all]<1.0,>=0.9->gradio) (0.4.6)\n",
            "Requirement already satisfied: shellingham<2.0.0,>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer[all]<1.0,>=0.9->gradio) (1.5.4)\n",
            "Requirement already satisfied: rich<14.0.0,>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from typer[all]<1.0,>=0.9->gradio) (13.7.0)\n",
            "Requirement already satisfied: h11>=0.8 in /usr/local/lib/python3.10/dist-packages (from uvicorn>=0.14.0->gradio) (0.14.0)\n",
            "Requirement already satisfied: anyio<4.0.0,>=3.7.1 in /usr/local/lib/python3.10/dist-packages (from fastapi->gradio) (3.7.1)\n",
            "Requirement already satisfied: starlette<0.28.0,>=0.27.0 in /usr/local/lib/python3.10/dist-packages (from fastapi->gradio) (0.27.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx->gradio) (2023.11.17)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx->gradio) (1.0.2)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from httpx->gradio) (3.6)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx->gradio) (1.3.0)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<4.0.0,>=3.7.1->fastapi->gradio) (1.2.0)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio) (23.1.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio) (2023.11.2)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio) (0.31.1)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio) (0.13.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib~=3.0->gradio) (1.16.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich<14.0.0,>=10.11.0->typer[all]<1.0,>=0.9->gradio) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich<14.0.0,>=10.11.0->typer[all]<1.0,>=0.9->gradio) (2.16.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.19.3->gradio) (3.3.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.19.3->gradio) (2.0.7)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich<14.0.0,>=10.11.0->typer[all]<1.0,>=0.9->gradio) (0.1.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade typing_extensions"
      ],
      "metadata": {
        "id": "9cYDXA-gy6kZ",
        "outputId": "cfd0ceef-1c6d-4b55-8932-29d8353fe264",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: typing_extensions in /usr/local/lib/python3.10/dist-packages (4.9.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --force-reinstall gradio"
      ],
      "metadata": {
        "id": "ee_a_JgFy6Y7",
        "outputId": "f8d5ca98-3fff-47fd-c005-7b9b91acc4d6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting gradio\n",
            "  Using cached gradio-4.9.0-py3-none-any.whl (16.6 MB)\n",
            "Collecting aiofiles<24.0,>=22.0 (from gradio)\n",
            "  Using cached aiofiles-23.2.1-py3-none-any.whl (15 kB)\n",
            "Collecting altair<6.0,>=4.2.0 (from gradio)\n",
            "  Using cached altair-5.2.0-py3-none-any.whl (996 kB)\n",
            "Collecting fastapi (from gradio)\n",
            "  Using cached fastapi-0.105.0-py3-none-any.whl (93 kB)\n",
            "Collecting ffmpy (from gradio)\n",
            "  Using cached ffmpy-0.3.1-py3-none-any.whl\n",
            "Collecting gradio-client==0.7.2 (from gradio)\n",
            "  Using cached gradio_client-0.7.2-py3-none-any.whl (304 kB)\n",
            "Collecting httpx (from gradio)\n",
            "  Using cached httpx-0.25.2-py3-none-any.whl (74 kB)\n",
            "Collecting huggingface-hub>=0.19.3 (from gradio)\n",
            "  Using cached huggingface_hub-0.19.4-py3-none-any.whl (311 kB)\n",
            "Collecting importlib-resources<7.0,>=1.3 (from gradio)\n",
            "  Using cached importlib_resources-6.1.1-py3-none-any.whl (33 kB)\n",
            "Collecting jinja2<4.0 (from gradio)\n",
            "  Using cached Jinja2-3.1.2-py3-none-any.whl (133 kB)\n",
            "Collecting markupsafe~=2.0 (from gradio)\n",
            "  Using cached MarkupSafe-2.1.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (25 kB)\n",
            "Collecting matplotlib~=3.0 (from gradio)\n",
            "  Using cached matplotlib-3.8.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.6 MB)\n",
            "Collecting numpy~=1.0 (from gradio)\n",
            "  Using cached numpy-1.26.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.2 MB)\n",
            "Collecting orjson~=3.0 (from gradio)\n",
            "  Using cached orjson-3.9.10-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (138 kB)\n",
            "Collecting packaging (from gradio)\n",
            "  Using cached packaging-23.2-py3-none-any.whl (53 kB)\n",
            "Collecting pandas<3.0,>=1.0 (from gradio)\n",
            "  Using cached pandas-2.1.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.3 MB)\n",
            "Collecting pillow<11.0,>=8.0 (from gradio)\n",
            "  Using cached Pillow-10.1.0-cp310-cp310-manylinux_2_28_x86_64.whl (3.6 MB)\n",
            "Collecting pydantic>=2.0 (from gradio)\n",
            "  Using cached pydantic-2.5.2-py3-none-any.whl (381 kB)\n",
            "Collecting pydub (from gradio)\n",
            "  Using cached pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
            "Collecting python-multipart (from gradio)\n",
            "  Using cached python_multipart-0.0.6-py3-none-any.whl (45 kB)\n",
            "Collecting pyyaml<7.0,>=5.0 (from gradio)\n",
            "  Using cached PyYAML-6.0.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (705 kB)\n",
            "Collecting semantic-version~=2.0 (from gradio)\n",
            "  Using cached semantic_version-2.10.0-py2.py3-none-any.whl (15 kB)\n",
            "Collecting tomlkit==0.12.0 (from gradio)\n",
            "  Using cached tomlkit-0.12.0-py3-none-any.whl (37 kB)\n",
            "Collecting typer[all]<1.0,>=0.9 (from gradio)\n",
            "  Using cached typer-0.9.0-py3-none-any.whl (45 kB)\n",
            "Collecting typing-extensions~=4.0 (from gradio)\n",
            "  Using cached typing_extensions-4.9.0-py3-none-any.whl (32 kB)\n",
            "Collecting uvicorn>=0.14.0 (from gradio)\n",
            "  Using cached uvicorn-0.24.0.post1-py3-none-any.whl (59 kB)\n",
            "Collecting fsspec (from gradio-client==0.7.2->gradio)\n",
            "  Using cached fsspec-2023.12.2-py3-none-any.whl (168 kB)\n",
            "Collecting websockets<12.0,>=10.0 (from gradio-client==0.7.2->gradio)\n",
            "  Using cached websockets-11.0.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (129 kB)\n",
            "Collecting jsonschema>=3.0 (from altair<6.0,>=4.2.0->gradio)\n",
            "  Using cached jsonschema-4.20.0-py3-none-any.whl (84 kB)\n",
            "Collecting toolz (from altair<6.0,>=4.2.0->gradio)\n",
            "  Using cached toolz-0.12.0-py3-none-any.whl (55 kB)\n",
            "Collecting filelock (from huggingface-hub>=0.19.3->gradio)\n",
            "  Using cached filelock-3.13.1-py3-none-any.whl (11 kB)\n",
            "Collecting requests (from huggingface-hub>=0.19.3->gradio)\n",
            "  Using cached requests-2.31.0-py3-none-any.whl (62 kB)\n",
            "Collecting tqdm>=4.42.1 (from huggingface-hub>=0.19.3->gradio)\n",
            "  Using cached tqdm-4.66.1-py3-none-any.whl (78 kB)\n",
            "Collecting contourpy>=1.0.1 (from matplotlib~=3.0->gradio)\n",
            "  Using cached contourpy-1.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (310 kB)\n",
            "Collecting cycler>=0.10 (from matplotlib~=3.0->gradio)\n",
            "  Using cached cycler-0.12.1-py3-none-any.whl (8.3 kB)\n",
            "Collecting fonttools>=4.22.0 (from matplotlib~=3.0->gradio)\n",
            "  Using cached fonttools-4.46.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.6 MB)\n",
            "Collecting kiwisolver>=1.3.1 (from matplotlib~=3.0->gradio)\n",
            "  Using cached kiwisolver-1.4.5-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.6 MB)\n",
            "Collecting pyparsing>=2.3.1 (from matplotlib~=3.0->gradio)\n",
            "  Using cached pyparsing-3.1.1-py3-none-any.whl (103 kB)\n",
            "Collecting python-dateutil>=2.7 (from matplotlib~=3.0->gradio)\n",
            "  Using cached python_dateutil-2.8.2-py2.py3-none-any.whl (247 kB)\n",
            "Collecting pytz>=2020.1 (from pandas<3.0,>=1.0->gradio)\n",
            "  Using cached pytz-2023.3.post1-py2.py3-none-any.whl (502 kB)\n",
            "Collecting tzdata>=2022.1 (from pandas<3.0,>=1.0->gradio)\n",
            "  Using cached tzdata-2023.3-py2.py3-none-any.whl (341 kB)\n",
            "Collecting annotated-types>=0.4.0 (from pydantic>=2.0->gradio)\n",
            "  Using cached annotated_types-0.6.0-py3-none-any.whl (12 kB)\n",
            "Collecting pydantic-core==2.14.5 (from pydantic>=2.0->gradio)\n",
            "  Using cached pydantic_core-2.14.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.1 MB)\n",
            "Collecting click<9.0.0,>=7.1.1 (from typer[all]<1.0,>=0.9->gradio)\n",
            "  Using cached click-8.1.7-py3-none-any.whl (97 kB)\n",
            "Collecting colorama<0.5.0,>=0.4.3 (from typer[all]<1.0,>=0.9->gradio)\n",
            "  Using cached colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
            "Collecting shellingham<2.0.0,>=1.3.0 (from typer[all]<1.0,>=0.9->gradio)\n",
            "  Using cached shellingham-1.5.4-py2.py3-none-any.whl (9.8 kB)\n",
            "Collecting rich<14.0.0,>=10.11.0 (from typer[all]<1.0,>=0.9->gradio)\n",
            "  Using cached rich-13.7.0-py3-none-any.whl (240 kB)\n",
            "Collecting h11>=0.8 (from uvicorn>=0.14.0->gradio)\n",
            "  Using cached h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "Collecting anyio<4.0.0,>=3.7.1 (from fastapi->gradio)\n",
            "  Using cached anyio-3.7.1-py3-none-any.whl (80 kB)\n",
            "Collecting starlette<0.28.0,>=0.27.0 (from fastapi->gradio)\n",
            "  Using cached starlette-0.27.0-py3-none-any.whl (66 kB)\n",
            "Collecting certifi (from httpx->gradio)\n",
            "  Using cached certifi-2023.11.17-py3-none-any.whl (162 kB)\n",
            "Collecting httpcore==1.* (from httpx->gradio)\n",
            "  Using cached httpcore-1.0.2-py3-none-any.whl (76 kB)\n",
            "Collecting idna (from httpx->gradio)\n",
            "  Using cached idna-3.6-py3-none-any.whl (61 kB)\n",
            "Collecting sniffio (from httpx->gradio)\n",
            "  Using cached sniffio-1.3.0-py3-none-any.whl (10 kB)\n",
            "Collecting exceptiongroup (from anyio<4.0.0,>=3.7.1->fastapi->gradio)\n",
            "  Using cached exceptiongroup-1.2.0-py3-none-any.whl (16 kB)\n",
            "Collecting attrs>=22.2.0 (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio)\n",
            "  Using cached attrs-23.1.0-py3-none-any.whl (61 kB)\n",
            "Collecting jsonschema-specifications>=2023.03.6 (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio)\n",
            "  Using cached jsonschema_specifications-2023.11.2-py3-none-any.whl (17 kB)\n",
            "Collecting referencing>=0.28.4 (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio)\n",
            "  Using cached referencing-0.32.0-py3-none-any.whl (26 kB)\n",
            "Collecting rpds-py>=0.7.1 (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio)\n",
            "  Using cached rpds_py-0.13.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "Collecting six>=1.5 (from python-dateutil>=2.7->matplotlib~=3.0->gradio)\n",
            "  Using cached six-1.16.0-py2.py3-none-any.whl (11 kB)\n",
            "Collecting markdown-it-py>=2.2.0 (from rich<14.0.0,>=10.11.0->typer[all]<1.0,>=0.9->gradio)\n",
            "  Using cached markdown_it_py-3.0.0-py3-none-any.whl (87 kB)\n",
            "Collecting pygments<3.0.0,>=2.13.0 (from rich<14.0.0,>=10.11.0->typer[all]<1.0,>=0.9->gradio)\n",
            "  Using cached pygments-2.17.2-py3-none-any.whl (1.2 MB)\n",
            "Collecting charset-normalizer<4,>=2 (from requests->huggingface-hub>=0.19.3->gradio)\n",
            "  Using cached charset_normalizer-3.3.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (142 kB)\n",
            "Collecting urllib3<3,>=1.21.1 (from requests->huggingface-hub>=0.19.3->gradio)\n",
            "  Using cached urllib3-2.1.0-py3-none-any.whl (104 kB)\n",
            "Collecting mdurl~=0.1 (from markdown-it-py>=2.2.0->rich<14.0.0,>=10.11.0->typer[all]<1.0,>=0.9->gradio)\n",
            "  Using cached mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
            "Installing collected packages: pytz, pydub, ffmpy, websockets, urllib3, tzdata, typing-extensions, tqdm, toolz, tomlkit, sniffio, six, shellingham, semantic-version, rpds-py, pyyaml, python-multipart, pyparsing, pygments, pillow, packaging, orjson, numpy, mdurl, markupsafe, kiwisolver, importlib-resources, idna, h11, fsspec, fonttools, filelock, exceptiongroup, cycler, colorama, click, charset-normalizer, certifi, attrs, annotated-types, aiofiles, uvicorn, typer, requests, referencing, python-dateutil, pydantic-core, markdown-it-py, jinja2, httpcore, contourpy, anyio, starlette, rich, pydantic, pandas, matplotlib, jsonschema-specifications, huggingface-hub, httpx, jsonschema, gradio-client, fastapi, altair, gradio\n",
            "  Attempting uninstall: pytz\n",
            "    Found existing installation: pytz 2023.3.post1\n",
            "    Uninstalling pytz-2023.3.post1:\n",
            "      Successfully uninstalled pytz-2023.3.post1\n",
            "  Attempting uninstall: pydub\n",
            "    Found existing installation: pydub 0.25.1\n",
            "    Uninstalling pydub-0.25.1:\n",
            "      Successfully uninstalled pydub-0.25.1\n",
            "  Attempting uninstall: ffmpy\n",
            "    Found existing installation: ffmpy 0.3.1\n",
            "    Uninstalling ffmpy-0.3.1:\n",
            "      Successfully uninstalled ffmpy-0.3.1\n",
            "  Attempting uninstall: websockets\n",
            "    Found existing installation: websockets 11.0.3\n",
            "    Uninstalling websockets-11.0.3:\n",
            "      Successfully uninstalled websockets-11.0.3\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 2.1.0\n",
            "    Uninstalling urllib3-2.1.0:\n",
            "      Successfully uninstalled urllib3-2.1.0\n",
            "  Attempting uninstall: tzdata\n",
            "    Found existing installation: tzdata 2023.3\n",
            "    Uninstalling tzdata-2023.3:\n",
            "      Successfully uninstalled tzdata-2023.3\n",
            "  Attempting uninstall: typing-extensions\n",
            "    Found existing installation: typing_extensions 4.9.0\n",
            "    Uninstalling typing_extensions-4.9.0:\n",
            "      Successfully uninstalled typing_extensions-4.9.0\n",
            "  Attempting uninstall: tqdm\n",
            "    Found existing installation: tqdm 4.66.1\n",
            "    Uninstalling tqdm-4.66.1:\n",
            "      Successfully uninstalled tqdm-4.66.1\n",
            "  Attempting uninstall: toolz\n",
            "    Found existing installation: toolz 0.12.0\n",
            "    Uninstalling toolz-0.12.0:\n",
            "      Successfully uninstalled toolz-0.12.0\n",
            "  Attempting uninstall: tomlkit\n",
            "    Found existing installation: tomlkit 0.12.0\n",
            "    Uninstalling tomlkit-0.12.0:\n",
            "      Successfully uninstalled tomlkit-0.12.0\n",
            "  Attempting uninstall: sniffio\n",
            "    Found existing installation: sniffio 1.3.0\n",
            "    Uninstalling sniffio-1.3.0:\n",
            "      Successfully uninstalled sniffio-1.3.0\n",
            "  Attempting uninstall: six\n",
            "    Found existing installation: six 1.16.0\n",
            "    Uninstalling six-1.16.0:\n",
            "      Successfully uninstalled six-1.16.0\n",
            "  Attempting uninstall: shellingham\n",
            "    Found existing installation: shellingham 1.5.4\n",
            "    Uninstalling shellingham-1.5.4:\n",
            "      Successfully uninstalled shellingham-1.5.4\n",
            "  Attempting uninstall: semantic-version\n",
            "    Found existing installation: semantic-version 2.10.0\n",
            "    Uninstalling semantic-version-2.10.0:\n",
            "      Successfully uninstalled semantic-version-2.10.0\n",
            "  Attempting uninstall: rpds-py\n",
            "    Found existing installation: rpds-py 0.13.2\n",
            "    Uninstalling rpds-py-0.13.2:\n",
            "      Successfully uninstalled rpds-py-0.13.2\n",
            "  Attempting uninstall: pyyaml\n",
            "    Found existing installation: PyYAML 6.0.1\n",
            "    Uninstalling PyYAML-6.0.1:\n",
            "      Successfully uninstalled PyYAML-6.0.1\n",
            "  Attempting uninstall: python-multipart\n",
            "    Found existing installation: python-multipart 0.0.6\n",
            "    Uninstalling python-multipart-0.0.6:\n",
            "      Successfully uninstalled python-multipart-0.0.6\n",
            "  Attempting uninstall: pyparsing\n",
            "    Found existing installation: pyparsing 3.1.1\n",
            "    Uninstalling pyparsing-3.1.1:\n",
            "      Successfully uninstalled pyparsing-3.1.1\n",
            "  Attempting uninstall: pygments\n",
            "    Found existing installation: Pygments 2.17.2\n",
            "    Uninstalling Pygments-2.17.2:\n",
            "      Successfully uninstalled Pygments-2.17.2\n",
            "  Attempting uninstall: pillow\n",
            "    Found existing installation: Pillow 10.1.0\n",
            "    Uninstalling Pillow-10.1.0:\n",
            "      Successfully uninstalled Pillow-10.1.0\n",
            "  Attempting uninstall: packaging\n",
            "    Found existing installation: packaging 23.2\n",
            "    Uninstalling packaging-23.2:\n",
            "      Successfully uninstalled packaging-23.2\n",
            "  Attempting uninstall: orjson\n",
            "    Found existing installation: orjson 3.9.10\n",
            "    Uninstalling orjson-3.9.10:\n",
            "      Successfully uninstalled orjson-3.9.10\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.26.2\n",
            "    Uninstalling numpy-1.26.2:\n",
            "      Successfully uninstalled numpy-1.26.2\n",
            "  Attempting uninstall: mdurl\n",
            "    Found existing installation: mdurl 0.1.2\n",
            "    Uninstalling mdurl-0.1.2:\n",
            "      Successfully uninstalled mdurl-0.1.2\n",
            "  Attempting uninstall: markupsafe\n",
            "    Found existing installation: MarkupSafe 2.1.3\n",
            "    Uninstalling MarkupSafe-2.1.3:\n",
            "      Successfully uninstalled MarkupSafe-2.1.3\n",
            "  Attempting uninstall: kiwisolver\n",
            "    Found existing installation: kiwisolver 1.4.5\n",
            "    Uninstalling kiwisolver-1.4.5:\n",
            "      Successfully uninstalled kiwisolver-1.4.5\n",
            "  Attempting uninstall: importlib-resources\n",
            "    Found existing installation: importlib-resources 6.1.1\n",
            "    Uninstalling importlib-resources-6.1.1:\n",
            "      Successfully uninstalled importlib-resources-6.1.1\n",
            "  Attempting uninstall: idna\n",
            "    Found existing installation: idna 3.6\n",
            "    Uninstalling idna-3.6:\n",
            "      Successfully uninstalled idna-3.6\n",
            "  Attempting uninstall: h11\n",
            "    Found existing installation: h11 0.14.0\n",
            "    Uninstalling h11-0.14.0:\n",
            "      Successfully uninstalled h11-0.14.0\n",
            "  Attempting uninstall: fsspec\n",
            "    Found existing installation: fsspec 2023.12.2\n",
            "    Uninstalling fsspec-2023.12.2:\n",
            "      Successfully uninstalled fsspec-2023.12.2\n",
            "  Attempting uninstall: fonttools\n",
            "    Found existing installation: fonttools 4.46.0\n",
            "    Uninstalling fonttools-4.46.0:\n",
            "      Successfully uninstalled fonttools-4.46.0\n",
            "  Attempting uninstall: filelock\n",
            "    Found existing installation: filelock 3.13.1\n",
            "    Uninstalling filelock-3.13.1:\n",
            "      Successfully uninstalled filelock-3.13.1\n",
            "  Attempting uninstall: exceptiongroup\n",
            "    Found existing installation: exceptiongroup 1.2.0\n",
            "    Uninstalling exceptiongroup-1.2.0:\n",
            "      Successfully uninstalled exceptiongroup-1.2.0\n",
            "  Attempting uninstall: cycler\n",
            "    Found existing installation: cycler 0.12.1\n",
            "    Uninstalling cycler-0.12.1:\n",
            "      Successfully uninstalled cycler-0.12.1\n",
            "  Attempting uninstall: colorama\n",
            "    Found existing installation: colorama 0.4.6\n",
            "    Uninstalling colorama-0.4.6:\n",
            "      Successfully uninstalled colorama-0.4.6\n",
            "  Attempting uninstall: click\n",
            "    Found existing installation: click 8.1.7\n",
            "    Uninstalling click-8.1.7:\n",
            "      Successfully uninstalled click-8.1.7\n",
            "  Attempting uninstall: charset-normalizer\n",
            "    Found existing installation: charset-normalizer 3.3.2\n",
            "    Uninstalling charset-normalizer-3.3.2:\n",
            "      Successfully uninstalled charset-normalizer-3.3.2\n",
            "  Attempting uninstall: certifi\n",
            "    Found existing installation: certifi 2023.11.17\n",
            "    Uninstalling certifi-2023.11.17:\n",
            "      Successfully uninstalled certifi-2023.11.17\n",
            "  Attempting uninstall: attrs\n",
            "    Found existing installation: attrs 23.1.0\n",
            "    Uninstalling attrs-23.1.0:\n",
            "      Successfully uninstalled attrs-23.1.0\n",
            "  Attempting uninstall: annotated-types\n",
            "    Found existing installation: annotated-types 0.6.0\n",
            "    Uninstalling annotated-types-0.6.0:\n",
            "      Successfully uninstalled annotated-types-0.6.0\n",
            "  Attempting uninstall: aiofiles\n",
            "    Found existing installation: aiofiles 23.2.1\n",
            "    Uninstalling aiofiles-23.2.1:\n",
            "      Successfully uninstalled aiofiles-23.2.1\n",
            "  Attempting uninstall: uvicorn\n",
            "    Found existing installation: uvicorn 0.24.0.post1\n",
            "    Uninstalling uvicorn-0.24.0.post1:\n",
            "      Successfully uninstalled uvicorn-0.24.0.post1\n",
            "  Attempting uninstall: typer\n",
            "    Found existing installation: typer 0.9.0\n",
            "    Uninstalling typer-0.9.0:\n",
            "      Successfully uninstalled typer-0.9.0\n",
            "  Attempting uninstall: requests\n",
            "    Found existing installation: requests 2.31.0\n",
            "    Uninstalling requests-2.31.0:\n",
            "      Successfully uninstalled requests-2.31.0\n",
            "  Attempting uninstall: referencing\n",
            "    Found existing installation: referencing 0.32.0\n",
            "    Uninstalling referencing-0.32.0:\n",
            "      Successfully uninstalled referencing-0.32.0\n",
            "  Attempting uninstall: python-dateutil\n",
            "    Found existing installation: python-dateutil 2.8.2\n",
            "    Uninstalling python-dateutil-2.8.2:\n",
            "      Successfully uninstalled python-dateutil-2.8.2\n",
            "  Attempting uninstall: pydantic-core\n",
            "    Found existing installation: pydantic_core 2.14.5\n",
            "    Uninstalling pydantic_core-2.14.5:\n",
            "      Successfully uninstalled pydantic_core-2.14.5\n",
            "  Attempting uninstall: markdown-it-py\n",
            "    Found existing installation: markdown-it-py 3.0.0\n",
            "    Uninstalling markdown-it-py-3.0.0:\n",
            "      Successfully uninstalled markdown-it-py-3.0.0\n",
            "  Attempting uninstall: jinja2\n",
            "    Found existing installation: Jinja2 3.1.2\n",
            "    Uninstalling Jinja2-3.1.2:\n",
            "      Successfully uninstalled Jinja2-3.1.2\n",
            "  Attempting uninstall: httpcore\n",
            "    Found existing installation: httpcore 1.0.2\n",
            "    Uninstalling httpcore-1.0.2:\n",
            "      Successfully uninstalled httpcore-1.0.2\n",
            "  Attempting uninstall: contourpy\n",
            "    Found existing installation: contourpy 1.2.0\n",
            "    Uninstalling contourpy-1.2.0:\n",
            "      Successfully uninstalled contourpy-1.2.0\n",
            "  Attempting uninstall: anyio\n",
            "    Found existing installation: anyio 3.7.1\n",
            "    Uninstalling anyio-3.7.1:\n",
            "      Successfully uninstalled anyio-3.7.1\n",
            "  Attempting uninstall: starlette\n",
            "    Found existing installation: starlette 0.27.0\n",
            "    Uninstalling starlette-0.27.0:\n",
            "      Successfully uninstalled starlette-0.27.0\n",
            "  Attempting uninstall: rich\n",
            "    Found existing installation: rich 13.7.0\n",
            "    Uninstalling rich-13.7.0:\n",
            "      Successfully uninstalled rich-13.7.0\n",
            "  Attempting uninstall: pydantic\n",
            "    Found existing installation: pydantic 2.5.2\n",
            "    Uninstalling pydantic-2.5.2:\n",
            "      Successfully uninstalled pydantic-2.5.2\n",
            "  Attempting uninstall: pandas\n",
            "    Found existing installation: pandas 2.1.4\n",
            "    Uninstalling pandas-2.1.4:\n",
            "      Successfully uninstalled pandas-2.1.4\n",
            "  Attempting uninstall: matplotlib\n",
            "    Found existing installation: matplotlib 3.8.2\n",
            "    Uninstalling matplotlib-3.8.2:\n",
            "      Successfully uninstalled matplotlib-3.8.2\n",
            "  Attempting uninstall: jsonschema-specifications\n",
            "    Found existing installation: jsonschema-specifications 2023.11.2\n",
            "    Uninstalling jsonschema-specifications-2023.11.2:\n",
            "      Successfully uninstalled jsonschema-specifications-2023.11.2\n",
            "  Attempting uninstall: huggingface-hub\n",
            "    Found existing installation: huggingface-hub 0.19.4\n",
            "    Uninstalling huggingface-hub-0.19.4:\n",
            "      Successfully uninstalled huggingface-hub-0.19.4\n",
            "  Attempting uninstall: httpx\n",
            "    Found existing installation: httpx 0.25.2\n",
            "    Uninstalling httpx-0.25.2:\n",
            "      Successfully uninstalled httpx-0.25.2\n",
            "  Attempting uninstall: jsonschema\n",
            "    Found existing installation: jsonschema 4.20.0\n",
            "    Uninstalling jsonschema-4.20.0:\n",
            "      Successfully uninstalled jsonschema-4.20.0\n",
            "  Attempting uninstall: gradio-client\n",
            "    Found existing installation: gradio_client 0.7.2\n",
            "    Uninstalling gradio_client-0.7.2:\n",
            "      Successfully uninstalled gradio_client-0.7.2\n",
            "  Attempting uninstall: fastapi\n",
            "    Found existing installation: fastapi 0.105.0\n",
            "    Uninstalling fastapi-0.105.0:\n",
            "      Successfully uninstalled fastapi-0.105.0\n",
            "  Attempting uninstall: altair\n",
            "    Found existing installation: altair 5.2.0\n",
            "    Uninstalling altair-5.2.0:\n",
            "      Successfully uninstalled altair-5.2.0\n",
            "  Attempting uninstall: gradio\n",
            "    Found existing installation: gradio 4.9.0\n",
            "    Uninstalling gradio-4.9.0:\n",
            "      Successfully uninstalled gradio-4.9.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "ipython 7.34.0 requires jedi>=0.16, which is not installed.\n",
            "lida 0.0.10 requires kaleido, which is not installed.\n",
            "llmx 0.0.15a0 requires cohere, which is not installed.\n",
            "llmx 0.0.15a0 requires openai, which is not installed.\n",
            "llmx 0.0.15a0 requires tiktoken, which is not installed.\n",
            "cupy-cuda11x 11.0.0 requires numpy<1.26,>=1.20, but you have numpy 1.26.2 which is incompatible.\n",
            "gcsfs 2023.6.0 requires fsspec==2023.6.0, but you have fsspec 2023.12.2 which is incompatible.\n",
            "google-colab 1.0.0 requires pandas==1.5.3, but you have pandas 2.1.4 which is incompatible.\n",
            "imageio 2.31.6 requires pillow<10.1.0,>=8.3.2, but you have pillow 10.1.0 which is incompatible.\n",
            "tensorflow-probability 0.22.0 requires typing-extensions<4.6.0, but you have typing-extensions 4.9.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed aiofiles-23.2.1 altair-5.2.0 annotated-types-0.6.0 anyio-3.7.1 attrs-23.1.0 certifi-2023.11.17 charset-normalizer-3.3.2 click-8.1.7 colorama-0.4.6 contourpy-1.2.0 cycler-0.12.1 exceptiongroup-1.2.0 fastapi-0.105.0 ffmpy-0.3.1 filelock-3.13.1 fonttools-4.46.0 fsspec-2023.12.2 gradio-4.9.0 gradio-client-0.7.2 h11-0.14.0 httpcore-1.0.2 httpx-0.25.2 huggingface-hub-0.19.4 idna-3.6 importlib-resources-6.1.1 jinja2-3.1.2 jsonschema-4.20.0 jsonschema-specifications-2023.11.2 kiwisolver-1.4.5 markdown-it-py-3.0.0 markupsafe-2.1.3 matplotlib-3.8.2 mdurl-0.1.2 numpy-1.26.2 orjson-3.9.10 packaging-23.2 pandas-2.1.4 pillow-10.1.0 pydantic-2.5.2 pydantic-core-2.14.5 pydub-0.25.1 pygments-2.17.2 pyparsing-3.1.1 python-dateutil-2.8.2 python-multipart-0.0.6 pytz-2023.3.post1 pyyaml-6.0.1 referencing-0.32.0 requests-2.31.0 rich-13.7.0 rpds-py-0.13.2 semantic-version-2.10.0 shellingham-1.5.4 six-1.16.0 sniffio-1.3.0 starlette-0.27.0 tomlkit-0.12.0 toolz-0.12.0 tqdm-4.66.1 typer-0.9.0 typing-extensions-4.9.0 tzdata-2023.3 urllib3-2.1.0 uvicorn-0.24.0.post1 websockets-11.0.3\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "PIL",
                  "certifi",
                  "cycler",
                  "dateutil",
                  "kiwisolver",
                  "matplotlib",
                  "mpl_toolkits",
                  "six"
                ]
              }
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "import torch\n",
        "from PIL import Image\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision.models.detection import fasterrcnn_resnet50_fpn\n",
        "import os\n",
        "\n",
        "# Crear una instancia del modelo y cargar el estado\n",
        "model = fasterrcnn_resnet50_fpn(pretrained=False, num_classes=3)  # Asegúrate de usar las mismas configuraciones que cuando entrenaste el modelo\n",
        "model_path = '/content/drive/My Drive/Mushrooms/modelo_entrenado.pth'\n",
        "model.load_state_dict(torch.load(model_path))\n",
        "model.eval()\n",
        "\n",
        "# Definir función para procesar la predicción\n",
        "def process_prediction(prediction):\n",
        "    # Mapeo de índices de clases a etiquetas de clase\n",
        "    class_labels = {1: 'chicken', 2: 'chanterelle'}\n",
        "\n",
        "    # Obtener las cajas delimitadoras y las etiquetas de clase\n",
        "    boxes = prediction[0]['boxes'].cpu().numpy()\n",
        "    labels = prediction[0]['labels'].cpu().numpy()\n",
        "\n",
        "    # Formatear el resultado\n",
        "    result = []\n",
        "    for label, box in zip(labels, boxes):\n",
        "        if label in class_labels:\n",
        "            label_str = class_labels[label]\n",
        "            box_str = f\"({box[0]:.2f}, {box[1]:.2f}, {box[2]:.2f}, {box[3]:.2f})\"\n",
        "            result.append(f\"{label_str}: {box_str}\")\n",
        "\n",
        "    return result if result else [\"No objects detected\"]\n",
        "\n",
        "# Definir función predict\n",
        "def predict(image):\n",
        "    # Transformar y preparar la imagen\n",
        "    transform = transforms.Compose([\n",
        "        transforms.Resize((416, 416)),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "    ])\n",
        "    input_tensor = transform(image).unsqueeze(0)\n",
        "\n",
        "    # Realizar la inferencia\n",
        "    with torch.no_grad():\n",
        "        prediction = model(input_tensor)\n",
        "\n",
        "    # Procesar la predicción\n",
        "    return process_prediction(prediction)\n",
        "\n",
        "# Cargar imágenes de prueba\n",
        "test_images_dir = '/content/drive/My Drive/Mushrooms/test/images/'\n",
        "test_images = [os.path.join(test_images_dir, file) for file in os.listdir(test_images_dir) if file.endswith('.jpg')]\n",
        "\n",
        "# Crear la interfaz de Gradio\n",
        "iface = gr.Interface(fn=predict, inputs=\"image\", outputs=\"label\", examples=test_images)\n",
        "iface.launch()\n"
      ],
      "metadata": {
        "id": "vcBequp5yTfd",
        "outputId": "b17d1836-8c29-4423-c8c0-6ab79f3f3ed7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 715
        }
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
            "  warnings.warn(msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Setting queue=True in a Colab notebook requires sharing enabled. Setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "Running on public URL: https://b254c7628b71d6d1d1.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://b254c7628b71d6d1d1.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}